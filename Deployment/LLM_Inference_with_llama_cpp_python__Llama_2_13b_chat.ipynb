{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihaZyg2aYQpH"
      },
      "source": [
        "# llama-cpp-python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MDuvLwarQO8"
      },
      "source": [
        "The Python package provides simple bindings for the llama.cpp library, offering access to the C API via ctypes interface, a high-level Python API for text completion, OpenAI-like API, and LangChain compatibility. It supports multiple BLAS backends for faster processing and includes both high-level and low-level APIs, along with web server functionality.\n",
        "\n",
        "`llama.cpp`'s objective is to run the LLaMA model with 4-bit integer quantization on MacBook. It is a plain C/C++ implementation optimized for Apple silicon and x86 architectures, supporting various integer quantization and BLAS libraries. Originally a web chat example, it now serves as a development playground for ggml library features.\n",
        "\n",
        "`GGML`, a C library for machine learning, facilitates the distribution of large language models (LLMs). It utilizes quantization to enable efficient LLM execution on consumer hardware. GGML files contain binary-encoded data, including version number, hyperparameters, vocabulary, and weights. The vocabulary comprises tokens for language generation, while the weights determine the LLM's size. Quantization reduces precision to optimize resource usage."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GGML format has been replaced by GGUF, effective as of August 21st, 2023. Starting from this date, llama.cpp will no longer provide compatibility with GGML models. This notebook uses `llama-cpp-python==0.1.78, which is compatible with GGML Models`."
      ],
      "metadata": {
        "id": "V2WYqinVm8DB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBnzlAqYZM6_"
      },
      "source": [
        "| Code Credits | Link |\n",
        "| ----------- | ---- |\n",
        "| 🎉 llama-cpp-python | [![GitHub Repository](https://img.shields.io/github/stars/abetlen/llama-cpp-python?style=social)](https://github.com/abetlen/llama-cpp-python) |\n",
        "| 🎉 llama.cpp | [![GitHub Repository](https://img.shields.io/github/stars/ggerganov/llama.cpp?style=social)](https://github.com/ggerganov/llama.cpp) |\n",
        "| 🎉 GGML | [![GitHub Repository](https://img.shields.io/github/stars/ggerganov/ggml?style=social)](https://github.com/ggerganov/ggml) |\n",
        "| 🚀 Online inference | [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI) |\n",
        "| 🚀 Online inference | [![Replicate](https://replicate.com/google-research/frame-interpolation/badge)](https://replicate.com/replicate/llama70b-v2-chat)\n",
        " |\n",
        "| 🔥 Discover More Colab Notebooks | [![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-black?style=flat-square&logo=github)](https://github.com/R3gm/InsightSolver-Colab/) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rkl4zg7nLhJ"
      },
      "source": [
        "\n",
        "The library works the same with a CPU, but the inference can take about three times longer compared to using it on a GPU.\n",
        "\n",
        "If you want to use only the CPU, you can replace the content of the cell below with the following lines.\n",
        "```\n",
        "# CPU llama-cpp-python\n",
        "!pip install llama-cpp-python==0.1.78\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkBmY3vQvRSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5df2e0c-8f9f-4bbc-8cff-d7aef95adb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python==0.1.78\n",
            "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting setuptools>=42\n",
            "    Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "  Collecting scikit-build>=0.13\n",
            "    Downloading scikit_build-0.17.6-py3-none-any.whl (84 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.3/84.3 kB 1.3 MB/s eta 0:00:00\n",
            "  Collecting cmake>=3.18\n",
            "    Downloading cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.7/26.7 MB 15.2 MB/s eta 0:00:00\n",
            "  Collecting ninja\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 18.6 MB/s eta 0:00:00\n",
            "  Collecting distro (from scikit-build>=0.13)\n",
            "    Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "  Collecting packaging (from scikit-build>=0.13)\n",
            "    Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 5.0 MB/s eta 0:00:00\n",
            "  Collecting tomli (from scikit-build>=0.13)\n",
            "    Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\n",
            "    Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "  Installing collected packages: ninja, wheel, tomli, setuptools, packaging, distro, cmake, scikit-build\n",
            "    Creating /tmp/pip-build-env-fc82pknk/overlay/local/bin\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/wheel to 755\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/distro to 755\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-fc82pknk/overlay/local/bin/ctest to 755\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "  Successfully installed cmake-3.29.2 distro-1.9.0 ninja-1.11.1.1 packaging-24.0 scikit-build-0.17.6 setuptools-69.5.1 tomli-2.0.1 wheel-0.43.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info\n",
            "  writing /tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-wvoi3t7k/llama_cpp_python-0.1.78.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python==0.1.78)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m189.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m144.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "\n",
            "\n",
            "  --------------------------------------------------------------------------------\n",
            "  -- Trying 'Ninja' generator\n",
            "  --------------------------------\n",
            "  ---------------------------\n",
            "  ----------------------\n",
            "  -----------------\n",
            "  ------------\n",
            "  -------\n",
            "  --\n",
            "  CMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "    Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "    CMake.\n",
            "\n",
            "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "    CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "  Not searching for unused variables given on the command line.\n",
            "\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Configuring done (0.9s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_cmake_test_compile/build\n",
            "  --\n",
            "  -------\n",
            "  ------------\n",
            "  -----------------\n",
            "  ----------------------\n",
            "  ---------------------------\n",
            "  --------------------------------\n",
            "  -- Trying 'Ninja' generator - success\n",
            "  --------------------------------------------------------------------------------\n",
            "\n",
            "  Configuring Project\n",
            "    Working directory:\n",
            "      /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "    Command:\n",
            "      /tmp/pip-build-env-fc82pknk/overlay/local/lib/python3.10/dist-packages/cmake/data/bin/cmake /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-fc82pknk/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install -DPYTHON_VERSION_STRING:STRING=3.10.12 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/tmp/pip-build-env-fc82pknk/overlay/local/lib/python3.10/dist-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/usr/bin/python3 -DPYTHON_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPYTHON_LIBRARY:PATH=/usr/lib/x86_64-linux-gnu/libpython3.10.so -DPython_EXECUTABLE:PATH=/usr/bin/python3 -DPython_ROOT_DIR:PATH=/usr -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/usr/include/python3.10 -DPython3_EXECUTABLE:PATH=/usr/bin/python3 -DPython3_ROOT_DIR:PATH=/usr -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/usr/include/python3.10 -DCMAKE_MAKE_PROGRAM:FILEPATH=/tmp/pip-build-env-fc82pknk/overlay/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -DLLAMA_CUBLAS=on -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_CUBLAS=on\n",
            "\n",
            "  Not searching for unused variables given on the command line.\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  CMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\n",
            "    Git repository not found; to enable automatic generation of build info,\n",
            "    make sure Git is installed and the project is a Git repository.\n",
            "\n",
            "\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- cuBLAS found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  -- Configuring done (3.8s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-build\n",
            "  [1/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\n",
            "  [2/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\n",
            "  [3/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\n",
            "  [4/9] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\n",
            "  [5/9] Building CUDA object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [6/9] Linking CUDA shared library vendor/llama.cpp/libggml_shared.so\n",
            "  [7/9] Linking CXX shared library vendor/llama.cpp/libllama.so\n",
            "  [8/9] Linking CUDA static library vendor/llama.cpp/libggml_static.a\n",
            "  [8/9] Install the project...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so\n",
            "  -- Installing: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py\n",
            "  -- Installing: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py\n",
            "  -- Installing: /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/_skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so\" to \"\"\n",
            "\n",
            "  copying llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py\n",
            "  copying llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py\n",
            "  copying llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py\n",
            "  copying llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py\n",
            "  copying llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py\n",
            "  copying llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py\n",
            "  creating directory _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server\n",
            "  copying llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py\n",
            "  copying llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py\n",
            "  copying llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py\n",
            "  copying /tmp/pip-install-c6ku0xmv/llama-cpp-python_841c7a21e783493595faf035efebf17a/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed\n",
            "\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server\n",
            "  copied 9 files\n",
            "  running build_ext\n",
            "  installing to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/utils.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_types.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_grammar.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/app.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__main__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/server/__init__.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp/server\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/py.typed -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama_cpp.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copying _skbuild/linux-x86_64-3.10/setuptools/lib.linux-x86_64-cpython-310/llama_cpp/llama.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp\n",
            "  copied 11 files\n",
            "  running install_data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libllama.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/lib/libggml_shared.so -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  copying _skbuild/linux-x86_64-3.10/cmake-install/bin/convert.py -> _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing llama_cpp_python.egg-info/PKG-INFO\n",
            "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
            "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
            "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
            "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE.md'\n",
            "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
            "  Copying llama_cpp_python.egg-info to _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  copied 0 files\n",
            "  creating _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-11_5rum1/.tmp-8sj7t4vz/llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl' and adding '_skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'llama_cpp/__init__.py'\n",
            "  adding 'llama_cpp/libllama.so'\n",
            "  adding 'llama_cpp/llama.py'\n",
            "  adding 'llama_cpp/llama_cpp.py'\n",
            "  adding 'llama_cpp/llama_grammar.py'\n",
            "  adding 'llama_cpp/llama_types.py'\n",
            "  adding 'llama_cpp/py.typed'\n",
            "  adding 'llama_cpp/utils.py'\n",
            "  adding 'llama_cpp/server/__init__.py'\n",
            "  adding 'llama_cpp/server/__main__.py'\n",
            "  adding 'llama_cpp/server/app.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.so'\n",
            "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.so'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/LICENSE.md'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\n",
            "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\n",
            "  removing _skbuild/linux-x86_64-3.10/setuptools/bdist.linux-x86_64/wheel\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp310-cp310-linux_x86_64.whl size=5811132 sha256=9461800fe48c69f668771ca51459aae3a796338b0e9aa59793f689498f60bba2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b7s0sqr7/wheels/61/f9/20/9ca660a9d3f2a47e44217059409478865948b5c8a1cba70030\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/__pycache__/typing_extensions.cpython-310.pyc\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions-4.11.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/typing_extensions.py\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/bin/f2py3\n",
            "      Removing file or directory /usr/local/bin/f2py3.10\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.26.4 typing-extensions-4.11.0\n"
          ]
        }
      ],
      "source": [
        "# GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 --force-reinstall --upgrade --no-cache-dir --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_nBHTYSoIWV",
        "outputId": "f504e262-9fc8-4f45-e87d-827a2a7c707e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.16.4\n"
          ]
        }
      ],
      "source": [
        "# For download the models\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install huggingface_hub"
      ],
      "metadata": {
        "id": "qykmGRucCnfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "model_id=\"ruslanmv/Medical-Llama3-8B\"\n",
        "snapshot_download(repo_id=model_id, local_dir=\"Medical-Llama3-8B\",\n",
        "                  local_dir_use_symlinks=False, revision=\"main\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595,
          "referenced_widgets": [
            "859e4a6bd3d34e83ad9eb9473c68b8d9",
            "87c4e37b74ea406cb3439b7d57297c7b",
            "e9d8b40a4fac499dafa2188583a4ec69",
            "12346cd265654e339ca619d26ce23123",
            "f1326ab2dad84d1fb3169dd5668959fd",
            "a877cd023dcf4e8ba7850caf2df839e2",
            "4a5175bdcda74227acac52efbb2043f9",
            "631bae1792404ca4acdbbbe4a3b372e2",
            "501d78fdc86d4ce38f25705a26aa157d",
            "89229a74aad44c8cb13137cbf6c7ea77",
            "feefc6aa5580415da6d3d5f71023da07",
            "61376fc06bab456eb7d8b8473b9f9cdf",
            "7b5316b5ced041fcb2126910be73031b",
            "4adcb388de504994858c83d0b05bdb3c",
            "320148891056456fb628746040900e17",
            "c23d086f548e4293829b3a4820712d72",
            "a3479bc2acda461988232e4385aadfb7",
            "5a3b69f07cff41198a2cdf23c0e75ddb",
            "3d281bbfc70743c8a512e9582e98127c",
            "8b816771318e4202805f82c3c464bf89",
            "28c3c5dbe6674e8d8e6492a603436bc8",
            "3b2f2be3e09442e3be0689b4b1d61958",
            "3d3f3d8a001b4d20ae408d4eac24f61a",
            "a1d0ae31e0aa427b9613c9556d2ad53b",
            "a4d590a5ac384894b6edfe64c3b0c48a",
            "11df6b84180d49ddbf663d34511608c0",
            "9ee4dd8653884f7aa627c7c016c71ac9",
            "58217369fc3548f481aa2c939099d256",
            "fa8a279d097a441fa4f1b1663b871886",
            "c0bc65aa903d44c588a9a2f470c48240",
            "1083e9b1f8d949d7a0d8aba001f19c9e",
            "f16b247cff23429496d81548b78213cd",
            "8b62d28b9ba44ea1805ea97b9d2cf5cd",
            "b83c564de27c4ec790ba01b73e683588",
            "c5f834f7cd8243dd9572b6ed07ebc02c",
            "d7e6aac9a119465087594f1b94834713",
            "07c022f3837c40c98a38bf4eb4d19ae8",
            "9a00def87e834e91ad031732295dcc6f",
            "d40b7e7ead8e4242a33e3f1902d9a257",
            "4c26e5dc430143cbb11674f8772039ee",
            "97e2b0aef94e4fd6a3aef3fc44dc74ef",
            "4a39efb4ac0a4ca9bce437b58c831adb",
            "b7cd82dfbb604074b70d13685b823a2a",
            "6d0310ff84324585a688a35dcdb772a7",
            "e13ef424c8b840c1aa58e027762f460c",
            "7b97d27876904f87a35ab63d17aab398",
            "5e5b1f7c549946a098f3f64b4de5a64d",
            "c17676bc69cc44ed986f6331a012a002",
            "cfb8f83fcfec445d958007eb0b215fee",
            "9d5e29407bf449298b93a8d71a914faf",
            "5cea003dca1b4d9bbe817cc8b267c13b",
            "b02f5b2edb9c476aa0a98abb48201f7a",
            "7134aef8454b4bbba035a78739355e72",
            "13f9c419380e486398b5266fa19a4e6f",
            "094bedab38b84376b354fb9ab2f135c2",
            "2a81997a7d204e1e8c23016daf3ce45a",
            "c51e5f8dbd1b4af2b602f975e68079ee",
            "ef338cb1b4924b39ba56a9ca2f9f8afb",
            "7e79e414856c4f09a01b5c06a05f9529",
            "fdfd1384cd6f4556b2cfeccde7a8590f",
            "295305472d044f81952f33134bf9d9b9",
            "1bb4f15c10c942028097a007d06f66db",
            "f0c382c8b7a641f4ae2a5cc8caa98c74",
            "b1add2bae15f4f71a958c449186eda45",
            "c7a6eb1eddc74933b29c99e87d7b2f6b",
            "6373de7a3d31405ab035437d55bc5892",
            "2025a848f4b1429bb053c2731dd0bd81",
            "d64b6bf0f4514a33b64903af7f17ccab",
            "4afc55ef689548839eab95332023bdd6",
            "79ca4b3020df4ddbae2c2faba32548ce",
            "73295c2926ff46db971fda0add16b1d3",
            "5c8e97b584c74a819d2a41751ff466d8",
            "1e51b3c50a1a48e9a647a0d6d1f90fa8",
            "fef5cd8123884d999ed4504f3db8c546",
            "1d62ec7b54a1476b8718bee2c1660739",
            "cd77913ed8ee4b218f891580ce2a91fa",
            "bd3e23a8b0784be18b35250ed92bfb7a",
            "8b4bb98e4ebc43feb7f6630ee6b58f29",
            "f76ade7c030f48b29b8c3be019b87630",
            "6db53c52e5ee4bfab01d8d83a096d6d2",
            "dcfbf29270384575879f2d93459d0b32",
            "fae4c6c94ad341bd9dc1ebef9c78443f",
            "d1bb25561f83486d93c7c2929ee323c0",
            "c114f7e0e1eb41f3a7efd65fdefd2eba",
            "56f325c8da264e939d8e6fbe40c982a9",
            "936b36f891434164921eb4dfa618f298",
            "fbb12abf435c46358c92acdee2741924",
            "6d06a9b9b38b498e88d554f203f0a609",
            "d6c2d5d9318b4202b4241c3e48024653",
            "b14c908d865748198114c2aa9d945f3f",
            "5353d06a3399415a966f1cd2734e7049",
            "0edd3dd485de4bbfb7a37d23c3da3194",
            "fa1da5703cb041108801c7c9bc47b9bf",
            "d7d1f1a5ce2d44a59b5cb534c2cc0818",
            "c9571b0b445d4deda8338f10a79d25d8",
            "62365897684243adbdda83dded49b428",
            "fd8bfa0dc7c34a9e84dc2eacbe9b2649",
            "5cc3378198e84211a91c2604200b4a67",
            "3d2f5984856b41bc852f2d46892d8376",
            "4887ba81927547cd842da318683e86cb",
            "5c371bcfab2b4e4ab983ab45d973a6e4",
            "d400606b53524cb2a22d0f976e4d8444",
            "1d5deb293ece4d468a71c0bc8fbd7372",
            "ad30264481a1495ca882d3c2d3e4e5bf",
            "46be8f37e5ab4f3bba82a20a36535b29",
            "85ba77cda6d545cb949e676d91a200b3",
            "be6dc913a1cc453b810655933c7b335f",
            "d8a434bdb716490297f00bb4603d78e7",
            "f197cd51069247a586a26b1242f65bf2",
            "f77b70f135ca4c5b82e114da20032202",
            "a9da5f201554403ebdef80de380176f0",
            "a8a657c278de47c28635fc13a56c5149",
            "22536fe061c849c093b8aea2f3384488",
            "a7a1703a2eb7447daa149b5e84c78ad0",
            "4d46f823dc0646a987308bf0765be9d7",
            "dce912419b3e4b0490970915783d2bea",
            "32ae980128ce44b08af1fd807788b1ce",
            "b5302c1f72de4daf872de3f77bb344d1",
            "20b8323d567140048bd52a531e9c8ac6",
            "88741332c79147fa8db393e9b660b9da",
            "9f590f063af14e69914593add7e10e66",
            "1b98e4bdaf9b4dde8e83d17fe61290f4",
            "b44d08196ae44e289f4698075e015ae0",
            "f0a161d4e4b14cecb45d16bc09f6227d",
            "39f1a2b226764ab8ab62b2e578916b5b",
            "3acf505e3bee497d87e82bbf7760e2cf",
            "dc5bb686a1b646638284c54b1dae6395",
            "3628941016fe4bbb91ca1bcd52b622be",
            "944f94c251aa410eb7a3d69b6d676442",
            "8c5e99afdd7a4dd5b2e35566bde0849d",
            "b70f642ca4694b52ac5c2deb46330552",
            "2b5f238a9aae4195964d78155a48a586",
            "3901db51e63142c6923891df7cb5da79",
            "3877963d61414c98a333be689649855f",
            "52e62cc474e142daa32bf309c81bd024",
            "9040c9590c8a48fb99dca9ceab031e5d",
            "df83305501f340ea88b1313f0c58f78e",
            "225eb9ad19844c0bb43086f50bfdd558",
            "c8f2ec55143b4f22837ca123c268e01b",
            "c60dec5effb343ad90db88922fc56b06",
            "f03e176fbc63421fa908b478e9fbeaa3",
            "93567b3de3e64b66a5d27dd215a07011",
            "90e68b5d78784602a019227f6504fecb",
            "fc83d58390ff47cf8c8d05ef42e36a27",
            "d16c8b917067492cb0634304df90ffa5",
            "3dfc437bf0144249bcd799979e6010c7",
            "32ed590b15c04b5f9b696249b2259299",
            "6ac307d5c9ae4ce68f258097d734fa48",
            "dd546286107840b68f2e698cab561f2d",
            "4804cd4f3b6d4a798aadc417c13bc0a9",
            "b779add6a8f34e7dbdbf6156773fd930",
            "15824965122045de98d620e1046f3d37",
            "d729e9840eaf455f8582ca0ab2b7c2f2",
            "10ade03f95db45d3b39a7e512db4e8da"
          ]
        },
        "id": "UJqn55pdCnco",
        "outputId": "d0ae216d-44e0-43d3-d408-dc6a4dc1bf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "859e4a6bd3d34e83ad9eb9473c68b8d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61376fc06bab456eb7d8b8473b9f9cdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d3f3d8a001b4d20ae408d4eac24f61a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.09k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b83c564de27c4ec790ba01b73e683588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e13ef424c8b840c1aa58e027762f460c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "future.jpg:   0%|          | 0.00/607k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a81997a7d204e1e8c23016daf3ce45a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00004.bin:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2025a848f4b1429bb053c2731dd0bd81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00004.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b4bb98e4ebc43feb7f6630ee6b58f29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00003-of-00004.bin:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6c2d5d9318b4202b4241c3e48024653"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00004-of-00004.bin:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4887ba81927547cd842da318683e86cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9da5f201554403ebdef80de380176f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b98e4bdaf9b4dde8e83d17fe61290f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3901db51e63142c6923891df7cb5da79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc83d58390ff47cf8c8d05ef42e36a27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Medical-Llama3-8B'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l0Ako1eCnZj",
        "outputId": "cedbf42f-bdbe-486e-8511-98430e59e596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 22791, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 22791 (delta 9), reused 17 (delta 5), pack-reused 22766\u001b[K\n",
            "Receiving objects: 100% (22791/22791), 27.64 MiB | 20.31 MiB/s, done.\n",
            "Resolving deltas: 100% (16096/16096), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FxkpxCKrCnWT",
        "outputId": "4d4a0481-771a-466d-c715-9c7d69b88ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy~=1.24.4 (from -r llama.cpp/./requirements/requirements-convert.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece~=0.1.98 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.1.99)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.40.0)\n",
            "Collecting gguf>=0.1.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 4))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 5))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch~=2.1.1 (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops~=0.7.0 (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: triton, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gguf, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed einops-0.7.0 gguf-0.6.0 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 protobuf-4.25.3 torch-2.1.2 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "7dcc184f5839441fbfed117a152003b1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXuX50MSCnTh",
        "outputId": "3ea2fe9e-478c-4bfa-cef6-9d6273c58a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: convert.py [-h] [--dump] [--dump-single] [--vocab-only] [--no-vocab]\n",
            "                  [--outtype {f32,f16,q8_0}] [--vocab-dir VOCAB_DIR] [--vocab-type VOCAB_TYPE]\n",
            "                  [--outfile OUTFILE] [--ctx CTX] [--concurrency CONCURRENCY] [--big-endian]\n",
            "                  [--pad-vocab] [--skip-unknown]\n",
            "                  model\n",
            "\n",
            "Convert a LLaMA model to a GGML compatible file\n",
            "\n",
            "positional arguments:\n",
            "  model                 directory containing model file, or model file itself (*.pth, *.pt, *.bin)\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dump                don't convert, just show what's in the model\n",
            "  --dump-single         don't convert, just show what's in a single model file\n",
            "  --vocab-only          extract only the vocab\n",
            "  --no-vocab            store model without the vocab\n",
            "  --outtype {f32,f16,q8_0}\n",
            "                        output format - note: q8_0 may be very slow (default: f16 or f32 based on\n",
            "                        input)\n",
            "  --vocab-dir VOCAB_DIR\n",
            "                        directory containing tokenizer.model, if separate from model file\n",
            "  --vocab-type VOCAB_TYPE\n",
            "                        vocab types to try in order, choose from 'spm', 'bpe', 'hfft' (default:\n",
            "                        spm,hfft)\n",
            "  --outfile OUTFILE     path to write to; default: based on input\n",
            "  --ctx CTX             model training context (default: based on input)\n",
            "  --concurrency CONCURRENCY\n",
            "                        concurrency used for conversion (default: 8)\n",
            "  --big-endian          model is executed on big endian machine\n",
            "  --pad-vocab           add pad tokens when model vocab expects more than tokenizer metadata\n",
            "                        provides\n",
            "  --skip-unknown        skip unknown tensor names instead of failing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py Medical-Llama3-8B \\\n",
        "  --outfile Medical-Llama3-8B.q8_0.gguf \\\n",
        "  --outtype q8_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WgJUh4vCnQX",
        "outputId": "f784c302-d62f-4435-c63f-7ac35d28cd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file Medical-Llama3-8B/pytorch_model-00001-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00001-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00002-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00003-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00004-of-00004.bin\n",
            "params = Params(n_vocab=128256, n_embd=4096, n_layer=32, n_ctx=8192, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=500000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyQ8_0: 7>, path_model=PosixPath('Medical-Llama3-8B'))\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/llama.cpp/convert.py\", line 1555, in <module>\n",
            "    main()\n",
            "  File \"/content/llama.cpp/convert.py\", line 1522, in main\n",
            "    vocab, special_vocab = vocab_factory.load_vocab(vocab_types, model_parent_path)\n",
            "  File \"/content/llama.cpp/convert.py\", line 1424, in load_vocab\n",
            "    vocab = self._create_vocab_by_path(vocab_types)\n",
            "  File \"/content/llama.cpp/convert.py\", line 1414, in _create_vocab_by_path\n",
            "    raise FileNotFoundError(f\"Could not find a tokenizer matching any of {vocab_types}\")\n",
            "FileNotFoundError: Could not find a tokenizer matching any of ['spm', 'hfft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py Medical-Llama3-8B \\\n",
        "--outfile Medical-Llama3-8B.q8_0.gguf \\\n",
        "--outtype q8_0 \\\n",
        "--vocab-type bpe,spm,hfft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9VhId03CnNg",
        "outputId": "5a4d62f3-2351-40d8-f94b-d104cc81048a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file Medical-Llama3-8B/pytorch_model-00001-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00001-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00002-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00003-of-00004.bin\n",
            "Loading model file Medical-Llama3-8B/pytorch_model-00004-of-00004.bin\n",
            "params = Params(n_vocab=128256, n_embd=4096, n_layer=32, n_ctx=8192, n_ff=14336, n_head=32, n_head_kv=8, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=500000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyQ8_0: 7>, path_model=PosixPath('Medical-Llama3-8B'))\n",
            "Loaded vocab file PosixPath('Medical-Llama3-8B/tokenizer.json'), type 'bpe'\n",
            "Vocab info: <BpeVocab with 128000 base tokens and 256 added tokens>\n",
            "Special vocab info: <SpecialVocab with 280147 merges, special tokens {'bos': 128000, 'eos': 128001, 'pad': 128001}, add special tokens unset>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [128256, 4096]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [4096, 4096]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [1024, 4096]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [4096, 4096]\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [14336, 4096]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [4096, 14336]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [4096]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [4096]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [4096]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [4096, 4096]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [1024, 4096]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [4096, 4096]\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [14336, 4096]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [4096, 14336]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [4096]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [4096]\n",
            "model.norm.weight                                -> output_norm.weight                       | F16    | [4096]\n",
            "lm_head.weight                                   -> output.weight                            | F16    | [128256, 4096]\n",
            "Writing Medical-Llama3-8B.q8_0.gguf, format 7\n",
            "Ignoring added_tokens.json since model matches vocab size without it.\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: Adding 280147 merge(s).\n",
            "gguf: Setting special token type bos to 128000\n",
            "gguf: Setting special token type eos to 128001\n",
            "gguf: Setting special token type pad to 128001\n",
            "/content/llama.cpp/convert.py:103: RuntimeWarning: invalid value encountered in divide\n",
            "  qs = (blocks / d[:, None]).round()\n",
            "[  1/291] Writing tensor token_embd.weight                      | size 128256 x   4096  | type Q8_0 | T+  51\n",
            "[  2/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "[  3/291] Writing tensor blk.0.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  57\n",
            "[  4/291] Writing tensor blk.0.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  57\n",
            "[  5/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "[  6/291] Writing tensor blk.0.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  57\n",
            "[  7/291] Writing tensor blk.0.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  57\n",
            "[  8/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  58\n",
            "[  9/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+  58\n",
            "[ 10/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+  58\n",
            "[ 11/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  60\n",
            "[ 12/291] Writing tensor blk.1.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  60\n",
            "[ 13/291] Writing tensor blk.1.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  60\n",
            "[ 14/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  63\n",
            "[ 15/291] Writing tensor blk.1.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  68\n",
            "[ 16/291] Writing tensor blk.1.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  70\n",
            "[ 17/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  72\n",
            "[ 18/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+  72\n",
            "[ 19/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+  72\n",
            "[ 20/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  72\n",
            "[ 21/291] Writing tensor blk.2.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  72\n",
            "[ 22/291] Writing tensor blk.2.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  72\n",
            "[ 23/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  72\n",
            "[ 24/291] Writing tensor blk.2.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  81\n",
            "[ 25/291] Writing tensor blk.2.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  82\n",
            "[ 26/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  84\n",
            "[ 27/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+  85\n",
            "[ 28/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+  85\n",
            "[ 29/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  85\n",
            "[ 30/291] Writing tensor blk.3.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  85\n",
            "[ 31/291] Writing tensor blk.3.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  85\n",
            "[ 32/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  85\n",
            "[ 33/291] Writing tensor blk.3.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+  93\n",
            "[ 34/291] Writing tensor blk.3.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+  95\n",
            "[ 35/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+  96\n",
            "[ 36/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+  97\n",
            "[ 37/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+  97\n",
            "[ 38/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  97\n",
            "[ 39/291] Writing tensor blk.4.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+  97\n",
            "[ 40/291] Writing tensor blk.4.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+  97\n",
            "[ 41/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  97\n",
            "[ 42/291] Writing tensor blk.4.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 106\n",
            "[ 43/291] Writing tensor blk.4.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 109\n",
            "[ 44/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 110\n",
            "[ 45/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+ 111\n",
            "[ 46/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+ 111\n",
            "[ 47/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 111\n",
            "[ 48/291] Writing tensor blk.5.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 111\n",
            "[ 49/291] Writing tensor blk.5.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 111\n",
            "[ 50/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 111\n",
            "[ 51/291] Writing tensor blk.5.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 119\n",
            "[ 52/291] Writing tensor blk.5.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 121\n",
            "[ 53/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 122\n",
            "[ 54/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+ 123\n",
            "[ 55/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+ 123\n",
            "[ 56/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 123\n",
            "[ 57/291] Writing tensor blk.6.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 123\n",
            "[ 58/291] Writing tensor blk.6.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 123\n",
            "[ 59/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 123\n",
            "[ 60/291] Writing tensor blk.6.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 132\n",
            "[ 61/291] Writing tensor blk.6.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 135\n",
            "[ 62/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 135\n",
            "[ 63/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+ 136\n",
            "[ 64/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+ 136\n",
            "[ 65/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 136\n",
            "[ 66/291] Writing tensor blk.7.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 136\n",
            "[ 67/291] Writing tensor blk.7.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 136\n",
            "[ 68/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 136\n",
            "[ 69/291] Writing tensor blk.7.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 145\n",
            "[ 70/291] Writing tensor blk.7.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 147\n",
            "[ 71/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 148\n",
            "[ 72/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+ 148\n",
            "[ 73/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+ 148\n",
            "[ 74/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 148\n",
            "[ 75/291] Writing tensor blk.8.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 148\n",
            "[ 76/291] Writing tensor blk.8.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 148\n",
            "[ 77/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 148\n",
            "[ 78/291] Writing tensor blk.8.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 157\n",
            "[ 79/291] Writing tensor blk.8.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 160\n",
            "[ 80/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 161\n",
            "[ 81/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+ 162\n",
            "[ 82/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+ 162\n",
            "[ 83/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+ 162\n",
            "[ 84/291] Writing tensor blk.9.attn_k.weight                    | size   1024 x   4096  | type Q8_0 | T+ 162\n",
            "[ 85/291] Writing tensor blk.9.attn_v.weight                    | size   1024 x   4096  | type Q8_0 | T+ 162\n",
            "[ 86/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+ 162\n",
            "[ 87/291] Writing tensor blk.9.ffn_gate.weight                  | size  14336 x   4096  | type Q8_0 | T+ 170\n",
            "[ 88/291] Writing tensor blk.9.ffn_up.weight                    | size  14336 x   4096  | type Q8_0 | T+ 173\n",
            "[ 89/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  14336  | type Q8_0 | T+ 174\n",
            "[ 90/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+ 174\n",
            "[ 91/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+ 174\n",
            "[ 92/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 174\n",
            "[ 93/291] Writing tensor blk.10.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 174\n",
            "[ 94/291] Writing tensor blk.10.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 174\n",
            "[ 95/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 174\n",
            "[ 96/291] Writing tensor blk.10.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 183\n",
            "[ 97/291] Writing tensor blk.10.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 185\n",
            "[ 98/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 186\n",
            "[ 99/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+ 187\n",
            "[100/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+ 187\n",
            "[101/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 187\n",
            "[102/291] Writing tensor blk.11.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 187\n",
            "[103/291] Writing tensor blk.11.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 187\n",
            "[104/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 187\n",
            "[105/291] Writing tensor blk.11.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 195\n",
            "[106/291] Writing tensor blk.11.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 198\n",
            "[107/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 199\n",
            "[108/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+ 199\n",
            "[109/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+ 199\n",
            "[110/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 199\n",
            "[111/291] Writing tensor blk.12.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 199\n",
            "[112/291] Writing tensor blk.12.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 199\n",
            "[113/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 199\n",
            "[114/291] Writing tensor blk.12.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 208\n",
            "[115/291] Writing tensor blk.12.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 211\n",
            "[116/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 212\n",
            "[117/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+ 212\n",
            "[118/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+ 213\n",
            "[119/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 213\n",
            "[120/291] Writing tensor blk.13.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 213\n",
            "[121/291] Writing tensor blk.13.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 213\n",
            "[122/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 213\n",
            "[123/291] Writing tensor blk.13.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 220\n",
            "[124/291] Writing tensor blk.13.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 224\n",
            "[125/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 225\n",
            "[126/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+ 225\n",
            "[127/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+ 225\n",
            "[128/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 225\n",
            "[129/291] Writing tensor blk.14.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 225\n",
            "[130/291] Writing tensor blk.14.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 225\n",
            "[131/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 225\n",
            "[132/291] Writing tensor blk.14.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 234\n",
            "[133/291] Writing tensor blk.14.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 236\n",
            "[134/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 237\n",
            "[135/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+ 238\n",
            "[136/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+ 238\n",
            "[137/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 238\n",
            "[138/291] Writing tensor blk.15.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 238\n",
            "[139/291] Writing tensor blk.15.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 238\n",
            "[140/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 238\n",
            "[141/291] Writing tensor blk.15.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 245\n",
            "[142/291] Writing tensor blk.15.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 249\n",
            "[143/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 250\n",
            "[144/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+ 250\n",
            "[145/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+ 250\n",
            "[146/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 250\n",
            "[147/291] Writing tensor blk.16.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 250\n",
            "[148/291] Writing tensor blk.16.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 250\n",
            "[149/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 250\n",
            "[150/291] Writing tensor blk.16.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 258\n",
            "[151/291] Writing tensor blk.16.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 262\n",
            "[152/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 263\n",
            "[153/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+ 263\n",
            "[154/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+ 263\n",
            "[155/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 263\n",
            "[156/291] Writing tensor blk.17.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 263\n",
            "[157/291] Writing tensor blk.17.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 263\n",
            "[158/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 263\n",
            "[159/291] Writing tensor blk.17.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 271\n",
            "[160/291] Writing tensor blk.17.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 275\n",
            "[161/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 276\n",
            "[162/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+ 276\n",
            "[163/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+ 276\n",
            "[164/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 276\n",
            "[165/291] Writing tensor blk.18.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 276\n",
            "[166/291] Writing tensor blk.18.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 276\n",
            "[167/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 276\n",
            "[168/291] Writing tensor blk.18.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 284\n",
            "[169/291] Writing tensor blk.18.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 287\n",
            "[170/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 288\n",
            "[171/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+ 288\n",
            "[172/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+ 288\n",
            "[173/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 288\n",
            "[174/291] Writing tensor blk.19.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 289\n",
            "[175/291] Writing tensor blk.19.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 289\n",
            "[176/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 289\n",
            "[177/291] Writing tensor blk.19.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 296\n",
            "[178/291] Writing tensor blk.19.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 300\n",
            "[179/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 301\n",
            "[180/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+ 302\n",
            "[181/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+ 302\n",
            "[182/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 302\n",
            "[183/291] Writing tensor blk.20.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 302\n",
            "[184/291] Writing tensor blk.20.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 302\n",
            "[185/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 302\n",
            "[186/291] Writing tensor blk.20.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 310\n",
            "[187/291] Writing tensor blk.20.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 313\n",
            "[188/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 314\n",
            "[189/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+ 314\n",
            "[190/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+ 314\n",
            "[191/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 314\n",
            "[192/291] Writing tensor blk.21.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 315\n",
            "[193/291] Writing tensor blk.21.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 315\n",
            "[194/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 315\n",
            "[195/291] Writing tensor blk.21.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 322\n",
            "[196/291] Writing tensor blk.21.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 325\n",
            "[197/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 327\n",
            "[198/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+ 328\n",
            "[199/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+ 328\n",
            "[200/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 328\n",
            "[201/291] Writing tensor blk.22.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 328\n",
            "[202/291] Writing tensor blk.22.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 328\n",
            "[203/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 328\n",
            "[204/291] Writing tensor blk.22.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 335\n",
            "[205/291] Writing tensor blk.22.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 338\n",
            "[206/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 339\n",
            "[207/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+ 340\n",
            "[208/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+ 340\n",
            "[209/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 340\n",
            "[210/291] Writing tensor blk.23.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 340\n",
            "[211/291] Writing tensor blk.23.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 340\n",
            "[212/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 340\n",
            "[213/291] Writing tensor blk.23.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 348\n",
            "[214/291] Writing tensor blk.23.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 351\n",
            "[215/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 352\n",
            "[216/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+ 352\n",
            "[217/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+ 352\n",
            "[218/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 352\n",
            "[219/291] Writing tensor blk.24.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 352\n",
            "[220/291] Writing tensor blk.24.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 352\n",
            "[221/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 352\n",
            "[222/291] Writing tensor blk.24.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 361\n",
            "[223/291] Writing tensor blk.24.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 363\n",
            "[224/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 364\n",
            "[225/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+ 365\n",
            "[226/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+ 365\n",
            "[227/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 365\n",
            "[228/291] Writing tensor blk.25.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 365\n",
            "[229/291] Writing tensor blk.25.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 365\n",
            "[230/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 365\n",
            "[231/291] Writing tensor blk.25.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 374\n",
            "[232/291] Writing tensor blk.25.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 376\n",
            "[233/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 377\n",
            "[234/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+ 378\n",
            "[235/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+ 378\n",
            "[236/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 378\n",
            "[237/291] Writing tensor blk.26.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 378\n",
            "[238/291] Writing tensor blk.26.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 378\n",
            "[239/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 378\n",
            "[240/291] Writing tensor blk.26.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 386\n",
            "[241/291] Writing tensor blk.26.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 389\n",
            "[242/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 390\n",
            "[243/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+ 390\n",
            "[244/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+ 390\n",
            "[245/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 390\n",
            "[246/291] Writing tensor blk.27.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 391\n",
            "[247/291] Writing tensor blk.27.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 391\n",
            "[248/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 391\n",
            "[249/291] Writing tensor blk.27.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 399\n",
            "[250/291] Writing tensor blk.27.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 401\n",
            "[251/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 402\n",
            "[252/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+ 403\n",
            "[253/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+ 403\n",
            "[254/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 403\n",
            "[255/291] Writing tensor blk.28.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 403\n",
            "[256/291] Writing tensor blk.28.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 403\n",
            "[257/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 403\n",
            "[258/291] Writing tensor blk.28.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 412\n",
            "[259/291] Writing tensor blk.28.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 414\n",
            "[260/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 415\n",
            "[261/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+ 415\n",
            "[262/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+ 415\n",
            "[263/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 415\n",
            "[264/291] Writing tensor blk.29.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 416\n",
            "[265/291] Writing tensor blk.29.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 416\n",
            "[266/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 416\n",
            "[267/291] Writing tensor blk.29.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 424\n",
            "[268/291] Writing tensor blk.29.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 427\n",
            "[269/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 428\n",
            "[270/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 428\n",
            "[271/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 428\n",
            "[272/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 429\n",
            "[273/291] Writing tensor blk.30.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 429\n",
            "[274/291] Writing tensor blk.30.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 429\n",
            "[275/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 429\n",
            "[276/291] Writing tensor blk.30.ffn_gate.weight                 | size  14336 x   4096  | type Q8_0 | T+ 439\n",
            "[277/291] Writing tensor blk.30.ffn_up.weight                   | size  14336 x   4096  | type Q8_0 | T+ 443\n",
            "[278/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  14336  | type Q8_0 | T+ 444\n",
            "[279/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 445\n",
            "[280/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 445\n",
            "[281/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 445\n",
            "[282/291] Writing tensor blk.31.attn_k.weight                   | size   1024 x   4096  | type Q8_0 | T+ 446\n",
            "[283/291] Writing tensor blk.31.attn_v.weight                   | size   1024 x   4096  | type Q8_0 | T+ 449\n",
            "[284/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 449\n",
            "Process ForkProcess-8:\n",
            "Process ForkProcess-5:\n",
            "Process ForkProcess-1:\n",
            "Process ForkProcess-7:\n",
            "Process ForkProcess-3:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
            "    call_item = call_queue.get(block=True)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
            "    call_item = call_queue.get(block=True)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
            "    call_item = call_queue.get(block=True)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
            "    call_item = call_queue.get(block=True)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
            "    call_item = call_queue.get(block=True)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
            "    res = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "model_id = \"ruslanmv/Medical-Llama3-8B-GGUF\"\n",
        "api.create_repo(model_id, exist_ok=True, repo_type=\"model\")\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"Medical-Llama3-8B.q8_0.gguf\",\n",
        "    path_in_repo=\"Medical-Llama3-8B.q8_0.gguf\",\n",
        "    repo_id=model_id,\n",
        ")"
      ],
      "metadata": {
        "id": "BL6PqtwWCnKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert.py Medical-Llama3-8B \\\n",
        "--outfile Medical-Llama3-8B.q4_0.gguf \\\n",
        "--outtype q4_0 \\\n",
        "--vocab-type bpe,spm,hfft"
      ],
      "metadata": {
        "id": "sWbN6E2TCnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQuQuRqsCnEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RD5nI6dOCnBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmOk2KmRCm9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11KqY7lW0yv"
      },
      "source": [
        "# Select the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzJkCoRRbICP"
      },
      "source": [
        "\n",
        "First, we need to specify the model to use. In Colab with T4 GPU, we can run models of up to 20B of parameters with all optimizations, but this may degrade the quality of the model's inference. The library can run GGML models on a CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHAz1yGZb4lq"
      },
      "source": [
        "In this case, we will use a [Llama 2 13B-chat](https://huggingface.co/meta-llama/Llama-2-13b-chat) The Llama 2 is a collection of pretrained and fine-tuned generative text models, ranging from 7 billion to 70 billion parameters, designed for dialogue use cases. It outperforms open-source chat models on most benchmarks and is on par with popular closed-source models in human evaluations for helpfulness and safety.\n",
        "\n",
        "![asd](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc24dac6d-6b5e-4b5f-938c-05951c938a9e_1085x543.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdmNwEqjRcPY"
      },
      "source": [
        "# Model quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx-5Fgx80UXj"
      },
      "source": [
        "We can quantize the model using this library, but for practical purposes, it is better to use pre-quantized models. The resulting model is only compatible with libraries that support GGML.\n",
        "\n",
        "\n",
        "```\n",
        "# obtain the original LLaMA model weights and place them in ./models\n",
        "ls ./models\n",
        "65B 30B 13B 7B tokenizer_checklist.chk tokenizer.model\n",
        "\n",
        "# install Python dependencies\n",
        "python3 -m pip install -r requirements.txt\n",
        "\n",
        "# convert the 7B model to ggml FP16 format\n",
        "python3 convert.py models/7B/\n",
        "\n",
        "# quantize the model to 4-bits (using q4_0 method)\n",
        "./quantize ./models/7B/ggml-model-f16.bin ./models/7B/ggml-model-q4_0.bin q4_0\n",
        "\n",
        "# run the inference\n",
        "./main -m ./models/7B/ggml-model-q4_0.bin -n 128\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSeedwAFSay9"
      },
      "source": [
        "#  Quantized Models from the Hugging Face Community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QwfjGFYRM4g"
      },
      "source": [
        "The Hugging Face community provides quantized models, which allow us to efficiently and effectively utilize the model on the T4 GPU. It is important to consult reliable sources before using any model.\n",
        "\n",
        "There are several variations available, but the ones that interest us are based on the GGLM library.\n",
        "\n",
        "We can see the different variations that Llama-2-13B-GGML has [here](https://huggingface.co/models?search=llama%202%20ggml).\n",
        "\n",
        "\n",
        "\n",
        "In this case, we will use the model called [Llama-2-13B-chat-GGML](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TbhbyD9wIdy"
      },
      "source": [
        "![22.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prefix 'q5_1' signifies the quantization method we used. I won't delve into too many details, but to determine the best method in each case, I follow the rule that 'q8' yields superior responses at the cost of higher memory usage [slow]. On the other hand, 'q2' may generate subpar responses but requires less RAM [fast].\n",
        "\n",
        "There are other quantization methods available, and you can read about them in the [model card](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML)"
      ],
      "metadata": {
        "id": "4L7AZFe_7Px0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI-kXwg5bHF-"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path2 = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename2 = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format"
      ],
      "metadata": {
        "id": "vMB8tMSWB7RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"ruslanmv/Medical-Llama3-8B\"\n",
        "model_basename = \"Medical-Llama3-8B.q8_0.gguf\" # the model is in bin format"
      ],
      "metadata": {
        "id": "P5rR_Gt0KtQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"ruslanmv/Medical-Llama3-8B-GGUF-4bit\"\n",
        "model_basename = \"Medical-Llama3-8B-GGUF.Q4_0.gguf\" # the model is in bin format"
      ],
      "metadata": {
        "id": "S6vKwrrA-T7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Td05XSuiWdI"
      },
      "source": [
        "First, we download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "e7672b0ac3e4407f8869440328f6c67c",
            "dbdba2df173a485c8a8c95c4fc873608",
            "fde6b38dc06943b48ca8cd350a868e01",
            "099f2d4b14ec4f8e90a29311feb5d05f",
            "de6c914e251c45e0aec29d826d96a9c5",
            "b77956ae89834deaa0666c2c7cfde231",
            "655a28fce2ee4695b23f455e5fee4d5c",
            "57fb5f6b00ff47b3bef3435e8b11bf68",
            "f444cd04b4764a3b9a5aa798a6b0f386",
            "5d911f2a9a2a48a890fc56fb2eb7b484",
            "6b3400846dba4ca88cac2b105e2eb4bd"
          ]
        },
        "id": "cBEJr-G-2ht4",
        "outputId": "6fd4479f-f2e1-48d6-db74-45ad10dcd0b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Medical-Llama3-8B-GGUF.Q4_0.gguf:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7672b0ac3e4407f8869440328f6c67c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path2 = hf_hub_download(repo_id=model_name_or_path2, filename=model_basename2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "fcec2e54a9b34e048fcd9fa7f7f32d5c",
            "5ec2783147fa40969b85dad071964d98",
            "5e9e7f3b5b464a1990947785672e64cf",
            "070dfa7bb31b46689d8e17958ef5578f",
            "87697391b8cb49b8a75f96a4dd71f130",
            "ccc8d21cd835471fb02e54f6dc6487ca",
            "d17b30cf95324384a1f784d167b7f698",
            "df9633c585a04a909e94a3f633882fc8",
            "5ab8395b984d41ee97351f14183f0aeb",
            "b8b5a62f28c9457f83f027bd9217f21d",
            "233c124324be449da00a5370d8d6bf38"
          ]
        },
        "id": "jmb77LdGB--p",
        "outputId": "3b583e41-3394-44e7-95ec-2b3e08506354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-13b-chat.ggmlv3.q5_1.bin:   0%|          | 0.00/9.76G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcec2e54a9b34e048fcd9fa7f7f32d5c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eqGxN5DAAFtb",
        "outputId": "92a961d1-1a2e-4d51-f5fd-9c4a77180028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--ruslanmv--Medical-Llama3-8B-GGUF-4bit/snapshots/b6b7dcc3641b1be82f0172f0deb03adf1d39a050/Medical-Llama3-8B-GGUF.Q4_0.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!huggingface-cli download \\\n",
        "  ruslanmv/Medical-Llama3-8B-GGUF-8bit \\\n",
        "   Medical-Llama3-8B-GGUF.Q8_0.gguf \\\n",
        "  --local-dir . \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "9wxzd4B9ACWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"/content/Medical-Llama3-8B.gguf\""
      ],
      "metadata": {
        "id": "RZm7BdZTILcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "max1jwxvCSbm"
      },
      "source": [
        "# Inference with llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TOfnZpj394g"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "oY1bItJu4Zfv",
        "outputId": "0f95c93c-976c-4868-db47-7f2157622976"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ca4070f2caf1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_cpp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlama\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlcpp_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m lcpp_llm = Llama(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# CPU cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, n_ctx, n_parts, n_gpu_layers, seed, f16_kv, logits_all, vocab_only, use_mmap, use_mlock, embedding, n_threads, n_batch, last_n_tokens_size, lora_base, lora_path, low_vram, tensor_split, rope_freq_base, rope_freq_scale, n_gqa, rms_norm_eps, mul_mat_q, verbose)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 )\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# GPU\n",
        "from llama_cpp import Llama\n",
        "lcpp_llm = None\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=43, # Change this value based on your model and your GPU VRAM pool.\n",
        "    n_ctx=4096, # Context window\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For run in CPU\n",
        "```\n",
        "# CPU\n",
        "from llama_cpp import Llama\n",
        "\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    )\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UdZnPtB8-Bhx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeH6eWiKuaxW",
        "outputId": "cf3a1ea5-37ff-48ec-ea06-56d9587e3c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# See the number of layers in GPU\n",
        "lcpp_llm.params.n_gpu_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLEEOufGVlID"
      },
      "source": [
        "We will use this prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NzVIlMCVoVD"
      },
      "outputs": [],
      "source": [
        "prompt = \"Write a linear regression in python\"\n",
        "prompt_template=f'''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaFQjPhcFgfN"
      },
      "source": [
        "Generating response\n",
        "\n",
        "If you only use CPU, the response can take a long time. You can reduce the max_tokens to get a faster response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R76uxL293jTc",
        "outputId": "c9d109f0-8803-47b1-b297-af2cf2683d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
            "\n",
            "USER: Write a linear regression in python\n",
            "\n",
            "ASSISTANT:\n",
            "\n",
            "To write a linear regression in Python, you can use the scikit-learn library. Here is an example of how to do this:\n",
            "```\n",
            "from sklearn.linear_model import LinearRegression\n",
            "import pandas as pd\n",
            "\n",
            "# Load your dataset into a Pandas DataFrame\n",
            "df = pd.read_csv('your_data.csv')\n",
            "\n",
            "# Create a linear regression object and fit the data\n",
            "reg = LinearRegression()\n",
            "reg.fit(df[['x1', 'x2']], df['y'])\n",
            "\n",
            "# Print the coefficients\n",
            "print(reg.coef_)\n",
            "```\n",
            "This will print out the coefficients for your linear regression model. You can also use the `predict()` method to make predictions on new data, like this:\n",
            "```\n",
            "# Make a prediction on some new data\n",
            "new_data = pd.DataFrame({'x1': [2, 3], 'x2': [4, 5]})\n",
            "prediction = reg.predict(new_data)\n",
            "print(prediction)\n",
            "```\n",
            "This will print out the predicted values for your new data.\n",
            "\n",
            "I hope this helps! Let me know if you have any questions or need further assistance.\n"
          ]
        }
      ],
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=prompt_template,\n",
        "    max_tokens=256,\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    top_k=50,\n",
        "    stop = ['USER:'], # Dynamic stopping when such token is detected.\n",
        "    echo=True # return the prompt\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no531n827gI9"
      },
      "source": [
        "# Inference with langchain\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG2uFQFl7jrq",
        "outputId": "b5ae2201-4eb6-49f7-a51b-a5616199111b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kl8UYvXHYIt"
      },
      "source": [
        "We can use the model that we loaded earlier. However, for illustrative purposes, we will load one from the 'langchain' library. Due to vRAM limitations, before running these cells, you need to delete the previous model from memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWaQuYH0AT1z"
      },
      "outputs": [],
      "source": [
        "lcpp_llm.reset()\n",
        "lcpp_llm.set_cache(None)\n",
        "lcpp_llm = None\n",
        "del lcpp_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Prompt for the model."
      ],
      "metadata": {
        "id": "scri08pVDp8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5ijTbW6_dI_"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "template = \"\"\"''SYSTEM: You are a helpful, respectful and honest assistant. Always answer as helpfully.\n",
        "USER: {question}\n",
        "ASSISTANT: \"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx06Ea1DH8ky"
      },
      "source": [
        "Stream tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVIXxNoIHOe_"
      },
      "outputs": [],
      "source": [
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "# Verbose is required to pass to the callback manager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2DHWIr-IEDE"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iipsXBGhHNjf",
        "outputId": "00fb9a1b-d985-4d70-d23a-7ec79f37f834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.\n",
        "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "\n",
        "# Loading model,\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path,\n",
        "    max_tokens=1024,\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,\n",
        "    n_ctx=4096, # Context window\n",
        "    stop = ['USER:'], # Dynamic stopping when such token is detected.\n",
        "    temperature = 0.4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ8kbRz2F9vi"
      },
      "source": [
        "Generating response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "Lw4MaS4WBlR-",
        "outputId": "722b9e87-f391-4463-aa15-dc545f7a6898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sure thing! Here is an example of how you could write a simple linear regression in Python using scikit-learn library:\n",
            "```\n",
            "from sklearn.linear_model import LinearRegression\n",
            "import pandas as pd\n",
            "\n",
            "# Load your dataset\n",
            "df = pd.read_csv('your_data.csv')\n",
            "\n",
            "# Create X and y vectors\n",
            "X = df[['feature1', 'feature2']]\n",
            "y = df['target']\n",
            "\n",
            "# Create a linear regression object and fit the data\n",
            "reg = LinearRegression()\n",
            "reg.fit(X, y)\n",
            "\n",
            "# Print the coefficients\n",
            "print(reg.coef_)\n",
            "\n",
            "# Print the R-squared value\n",
            "print(reg.score(X, y))\n",
            "```\n",
            "This code assumes that you have a CSV file containing your data, with the features in the first two columns and the target variable in the last column. It creates X and y vectors from the data, fits a linear regression model to the data using the `fit()` method, prints the coefficients of the model using the `coef_` attribute, and prints the R-squared value using the `score()` method.\n",
            "\n",
            "I hope this helps! Let me know if you have any questions or need further assistance.\n",
            "```\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure thing! Here is an example of how you could write a simple linear regression in Python using scikit-learn library:\\n```\\nfrom sklearn.linear_model import LinearRegression\\nimport pandas as pd\\n\\n# Load your dataset\\ndf = pd.read_csv('your_data.csv')\\n\\n# Create X and y vectors\\nX = df[['feature1', 'feature2']]\\ny = df['target']\\n\\n# Create a linear regression object and fit the data\\nreg = LinearRegression()\\nreg.fit(X, y)\\n\\n# Print the coefficients\\nprint(reg.coef_)\\n\\n# Print the R-squared value\\nprint(reg.score(X, y))\\n```\\nThis code assumes that you have a CSV file containing your data, with the features in the first two columns and the target variable in the last column. It creates X and y vectors from the data, fits a linear regression model to the data using the `fit()` method, prints the coefficients of the model using the `coef_` attribute, and prints the R-squared value using the `score()` method.\\n\\nI hope this helps! Let me know if you have any questions or need further assistance.\\n```\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"Write a simple linear regression in python\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with llama.cpp"
      ],
      "metadata": {
        "id": "IdTSFrMqF-yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use llama.cpp directly, we must clone the repository. In this example, we will use only the CPU."
      ],
      "metadata": {
        "id": "AjwqmnwYZlyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "!git checkout dadbed99e65252d79f81101a392d0d6497b86caa # For compatibility with GGML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwt3kdw4Rnmt",
        "outputId": "bbbcb889-4b78-4ded-a496-1f17faa43b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 7911, done.\u001b[K\n",
            "remote: Counting objects: 100% (4150/4150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (567/567), done.\u001b[K\n",
            "remote: Total 7911 (delta 3913), reused 3658 (delta 3582), pack-reused 3761\u001b[K\n",
            "Receiving objects: 100% (7911/7911), 7.34 MiB | 21.05 MiB/s, done.\n",
            "Resolving deltas: 100% (5488/5488), done.\n",
            "/content/llama.cpp\n",
            "Note: switching to 'dadbed99e65252d79f81101a392d0d6497b86caa'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at dadbed9 metal : fix synchronization in new matrix multiplication kernel (#2686)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build llama.cpp\n",
        "\n",
        "We will use the model only with the CPU."
      ],
      "metadata": {
        "id": "yjhMVxTVZ9o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "!make\n",
        "\n",
        "# GPU\n",
        "#!make LLAMA_CUBLAS=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E38icaHSLB_",
        "outputId": "a1f852d7-b838-4084-d0ae-81ffb0d50532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I llama.cpp build info: \n",
            "I UNAME_S:  Linux\n",
            "I UNAME_P:  x86_64\n",
            "I UNAME_M:  x86_64\n",
            "I CFLAGS:   -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS\n",
            "I CXXFLAGS: -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS\n",
            "I LDFLAGS:  \n",
            "I CC:       cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:      g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "cc  -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS   -c ggml.c -o ggml.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS -c llama.cpp -o llama.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS -c examples/common.cpp -o common.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS -c examples/console.cpp -o console.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS -c examples/grammar-parser.cpp -o grammar-parser.o\n",
            "cc -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS   -c -o k_quants.o k_quants.c\n",
            "cc  -I.              -O3 -std=c11   -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wdouble-promotion -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS   -c ggml-alloc.c -o ggml-alloc.o\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/main/main.cpp ggml.o llama.o common.o console.o grammar-parser.o k_quants.o ggml-alloc.o -o main \n",
            "\n",
            "====  Run ./main -h for help.  ====\n",
            "\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/quantize/quantize.cpp ggml.o llama.o k_quants.o ggml-alloc.o -o quantize \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/quantize-stats/quantize-stats.cpp ggml.o llama.o k_quants.o ggml-alloc.o -o quantize-stats \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/perplexity/perplexity.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o perplexity \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/embedding/embedding.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o embedding \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS pocs/vdot/vdot.cpp ggml.o k_quants.o ggml-alloc.o -o vdot \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/train-text-from-scratch/train-text-from-scratch.cpp ggml.o llama.o k_quants.o ggml-alloc.o -o train-text-from-scratch \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp ggml.o llama.o k_quants.o ggml-alloc.o -o convert-llama2c-to-ggml \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/simple/simple.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o simple \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS -Iexamples/server examples/server/server.cpp ggml.o llama.o common.o grammar-parser.o k_quants.o ggml-alloc.o -o server  \n",
            "g++ --shared -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/embd-input/embd-input-lib.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o libembdinput.so \n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/embd-input/embd-input-test.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o embd-input-test  -L. -lembdinput\n",
            "g++ -I. -I./examples -O3 -std=c++11 -fPIC -DNDEBUG -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-multichar -pthread -march=native -mtune=native -DGGML_USE_K_QUANTS examples/llama-bench/llama-bench.cpp ggml.o llama.o common.o k_quants.o ggml-alloc.o -o llama-bench \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./main -t 2 -m {model_path} --color -c 128 --temp 0.7 -n 56 -p \"USER: Write a linear regression in python\\nASSISTANT:\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMNdFcnte8-K",
        "outputId": "351ece94-4391-418d-f599-85b202c23ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: build = 852 (294f424)\n",
            "main: seed  = 1689809714\n",
            "llama.cpp: loading model from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/e3b15539668fb5740b42fa01e0e2f04ce1d0a3ee/llama-2-13b-chat.ggmlv3.q5_1.bin\n",
            "llama_model_load_internal: format     = ggjt v3 (latest)\n",
            "llama_model_load_internal: n_vocab    = 32000\n",
            "llama_model_load_internal: n_ctx      = 128\n",
            "llama_model_load_internal: n_embd     = 5120\n",
            "llama_model_load_internal: n_mult     = 256\n",
            "llama_model_load_internal: n_head     = 40\n",
            "llama_model_load_internal: n_layer    = 40\n",
            "llama_model_load_internal: n_rot      = 128\n",
            "llama_model_load_internal: freq_base  = 10000.0\n",
            "llama_model_load_internal: freq_scale = 1\n",
            "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
            "llama_model_load_internal: n_ff       = 13824\n",
            "llama_model_load_internal: model size = 13B\n",
            "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
            "llama_model_load_internal: mem required  = 11113.06 MB (+ 1608.00 MB per state)\n",
            "llama_new_context_with_model: kv self size  =  100.00 MB\n",
            "\n",
            "system_info: n_threads = 2 / 2 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
            "sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.700000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\n",
            "generate: n_ctx = 128, n_batch = 512, n_predict = 56, n_keep = 0\n",
            "\n",
            "\n",
            "\u001b[33m USER: Write a linear regression in python\\nASSISTANT:\u001b[0m Sure, here's an example of how to implement linear regression in Python using scikit-learn library.\n",
            "\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "\n",
            "llama_print_timings:        load time = 50655.89 ms\n",
            "llama_print_timings:      sample time =    70.93 ms /    56 runs   (    1.27 ms per token,   789.53 tokens per second)\n",
            "llama_print_timings: prompt eval time = 50291.40 ms /    16 tokens ( 3143.21 ms per token,     0.32 tokens per second)\n",
            "llama_print_timings:        eval time = 1488997.82 ms /    55 runs   (27072.69 ms per token,     0.04 tokens per second)\n",
            "llama_print_timings:       total time = 1539377.00 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Details about the different parameters."
      ],
      "metadata": {
        "id": "wwxfqy_daf5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<tbody><tr><td class=\"l\"></td><td class=\"l\"> </td><td class=\"l\"> <b>param value</b> </td><td class=\"l\"></td></tr>\n",
        "  <tr><td class=\"l\">  <code>-h</code> </td><td class=\"l\"> <code>--help</code> </td><td class=\"l\"> </td><td class=\"l\"> Show this help message and exit</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-i</code> </td><td class=\"l\"> <code>--interactive</code> </td><td class=\"l\"> </td><td class=\"l\"> Run in interactive mode</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--interactive-first</code> </td><td class=\"l\"> </td><td class=\"l\"> Run in interactive mode and wait for input right away</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>-ins</code>, <code>--instruct</code> </td><td class=\"l\">  </td><td class=\"l\"> Run in instruction mode (use with Alpaca models)</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-r</code> </td><td class=\"l\"> <code>--reverse-prompt</code> </td><td class=\"l\"> <code>PROMPT</code> </td><td class=\"l\"> Run in interactive mode and poll user input upon seeing <code>PROMPT</code> (can be specified more than once for multiple prompts).</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--color</code> </td><td class=\"l\">  </td><td class=\"l\"> Colorise output to distinguish prompt and user input from generations</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-s</code> </td><td class=\"l\"> <code>--seed</code> </td><td class=\"l\"> <code>SEED</code> </td><td class=\"l\"> Seed for random number generator (default: <code>-1</code>, use random seed for &lt;= 0)</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-t</code> </td><td class=\"l\"> <code>--threads</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Number of threads to use during computation (default: 12)</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-p</code> </td><td class=\"l\"> <code>--prompt</code> </td><td class=\"l\"> <code>PROMPT</code> </td><td class=\"l\"> Prompt to start generation with (default: empty)</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--random-prompt</code> </td><td class=\"l\"> </td><td class=\"l\"> Start with a randomized prompt.</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--in-prefix</code> </td><td class=\"l\"> <code>STRING</code> </td><td class=\"l\"> String to prefix user inputs with (default: empty)</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-f</code> </td><td class=\"l\"> <code>--file</code> </td><td class=\"l\"> <code>FNAME</code> </td><td class=\"l\"> Prompt file to start generation.</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-n</code> </td><td class=\"l\"> <code>--n_predict</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Number of tokens to predict (default: 128, -1 = infinity)</td></tr>\n",
        "  <tr><td class=\"l\">   </td><td class=\"l\"> <code>--top_k</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Top-k sampling (default: 40)</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--top_p</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Top-p sampling (default: 0.9)</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--repeat_last_n</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Last n tokens to consider for penalize (default: 64)</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--repeat_penalty</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Penalize repeat sequence of tokens (default: 1.1)</td></tr>\n",
        "  <tr><td class=\"l\"> <code>-c</code> </td><td class=\"l\"> <code>--ctx_size</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Size of the prompt context (default: <code>512</code>)</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--ignore-eos</code> </td><td class=\"l\"> </td><td class=\"l\"> Ignore end of stream token and continue generating</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--memory_f32</code> </td><td class=\"l\"> </td><td class=\"l\"> Use <code>f32</code> instead of <code>f16</code> for memory key+value</td></tr>\n",
        "  <tr><td class=\"l\"> </td><td class=\"l\"> <code>--temp</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Temperature (default: <code>0.8</code>)</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--n_parts</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Number of model parts (default: -1 = determine from dimensions)</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-b</code> </td><td class=\"l\"> <code>--batch_size</code> </td><td class=\"l\"> <code>N</code> </td><td class=\"l\"> Batch size for prompt processing (default: 8)</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--perplexity</code> </td><td class=\"l\"> </td><td class=\"l\"> Compute perplexity over the prompt</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--keep</code> </td><td class=\"l\">   </td><td class=\"l\"> Number of tokens to keep from the initial prompt (default: 0, -1 = all)</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--mlock</code> </td><td class=\"l\">  </td><td class=\"l\"> Force system to keep model in RAM rather than swapping or compressing</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--mtest</code> </td><td class=\"l\">  </td><td class=\"l\"> Determine the maximum memory usage needed to do inference for the given <code>n_batch</code> and <code>n_predict</code> parameters (uncomment the <code>\"used_mem\"</code> line in <code>llama.cpp</code> to see the results)</td></tr>\n",
        "  <tr><td class=\"l\">  </td><td class=\"l\"> <code>--verbose-prompt</code> </td><td class=\"l\">   </td><td class=\"l\"> Print prompt before generation</td></tr>\n",
        "  <tr><td class=\"l\">  <code>-m</code> </td><td class=\"l\"> <code>--model</code> </td><td class=\"l\"> <code>FNAME</code> </td><td class=\"l\"> Model path (default: <code>models/llama-7B/ggml-model.bin</code>)</td></tr>\n",
        "\n",
        "</tbody>"
      ],
      "metadata": {
        "id": "ZdNp0ixPevHC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQcO_xyCJyGZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# What is better: GPTQ or GGML?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU6o0MlQJ2K3"
      },
      "source": [
        "- GPTQ is a specific format for GPU only.\n",
        "\n",
        "- GGML is designed for CPU and Apple M series but can also offload some layers on the GPU\n",
        "\n",
        "- GGMLs like q4_2, q4_3, q5_0, q5_1 and q8_0 have superior inference quality and outperform GPTQ on benchmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "- [renenyffenegger.ch - LLaMA C++ Library](https://renenyffenegger.ch/notes/development/Artificial-intelligence/language-model/LLM/LLaMA/libs/llama_cpp/)\n",
        "- [LLaMA C++ Library Documentation](https://llama-cpp-python.readthedocs.io/en/latest/)\n",
        "- [MacOS Install with Metal GPU - LLaMA C++ Library Documentation](https://llama-cpp-python.readthedocs.io/en/latest/install/macos/)\n"
      ],
      "metadata": {
        "id": "YX8Fx_n8fWwe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "859e4a6bd3d34e83ad9eb9473c68b8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87c4e37b74ea406cb3439b7d57297c7b",
              "IPY_MODEL_e9d8b40a4fac499dafa2188583a4ec69",
              "IPY_MODEL_12346cd265654e339ca619d26ce23123"
            ],
            "layout": "IPY_MODEL_f1326ab2dad84d1fb3169dd5668959fd"
          }
        },
        "87c4e37b74ea406cb3439b7d57297c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a877cd023dcf4e8ba7850caf2df839e2",
            "placeholder": "​",
            "style": "IPY_MODEL_4a5175bdcda74227acac52efbb2043f9",
            "value": "Fetching 13 files: 100%"
          }
        },
        "e9d8b40a4fac499dafa2188583a4ec69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_631bae1792404ca4acdbbbe4a3b372e2",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_501d78fdc86d4ce38f25705a26aa157d",
            "value": 13
          }
        },
        "12346cd265654e339ca619d26ce23123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89229a74aad44c8cb13137cbf6c7ea77",
            "placeholder": "​",
            "style": "IPY_MODEL_feefc6aa5580415da6d3d5f71023da07",
            "value": " 13/13 [03:15&lt;00:00, 46.04s/it]"
          }
        },
        "f1326ab2dad84d1fb3169dd5668959fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a877cd023dcf4e8ba7850caf2df839e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5175bdcda74227acac52efbb2043f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "631bae1792404ca4acdbbbe4a3b372e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501d78fdc86d4ce38f25705a26aa157d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89229a74aad44c8cb13137cbf6c7ea77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feefc6aa5580415da6d3d5f71023da07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61376fc06bab456eb7d8b8473b9f9cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b5316b5ced041fcb2126910be73031b",
              "IPY_MODEL_4adcb388de504994858c83d0b05bdb3c",
              "IPY_MODEL_320148891056456fb628746040900e17"
            ],
            "layout": "IPY_MODEL_c23d086f548e4293829b3a4820712d72"
          }
        },
        "7b5316b5ced041fcb2126910be73031b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3479bc2acda461988232e4385aadfb7",
            "placeholder": "​",
            "style": "IPY_MODEL_5a3b69f07cff41198a2cdf23c0e75ddb",
            "value": "config.json: 100%"
          }
        },
        "4adcb388de504994858c83d0b05bdb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d281bbfc70743c8a512e9582e98127c",
            "max": 729,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b816771318e4202805f82c3c464bf89",
            "value": 729
          }
        },
        "320148891056456fb628746040900e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28c3c5dbe6674e8d8e6492a603436bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2f2be3e09442e3be0689b4b1d61958",
            "value": " 729/729 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "c23d086f548e4293829b3a4820712d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3479bc2acda461988232e4385aadfb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3b69f07cff41198a2cdf23c0e75ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d281bbfc70743c8a512e9582e98127c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b816771318e4202805f82c3c464bf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28c3c5dbe6674e8d8e6492a603436bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2f2be3e09442e3be0689b4b1d61958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d3f3d8a001b4d20ae408d4eac24f61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1d0ae31e0aa427b9613c9556d2ad53b",
              "IPY_MODEL_a4d590a5ac384894b6edfe64c3b0c48a",
              "IPY_MODEL_11df6b84180d49ddbf663d34511608c0"
            ],
            "layout": "IPY_MODEL_9ee4dd8653884f7aa627c7c016c71ac9"
          }
        },
        "a1d0ae31e0aa427b9613c9556d2ad53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58217369fc3548f481aa2c939099d256",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8a279d097a441fa4f1b1663b871886",
            "value": ".gitattributes: 100%"
          }
        },
        "a4d590a5ac384894b6edfe64c3b0c48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bc65aa903d44c588a9a2f470c48240",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1083e9b1f8d949d7a0d8aba001f19c9e",
            "value": 1519
          }
        },
        "11df6b84180d49ddbf663d34511608c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16b247cff23429496d81548b78213cd",
            "placeholder": "​",
            "style": "IPY_MODEL_8b62d28b9ba44ea1805ea97b9d2cf5cd",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 29.3kB/s]"
          }
        },
        "9ee4dd8653884f7aa627c7c016c71ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58217369fc3548f481aa2c939099d256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8a279d097a441fa4f1b1663b871886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0bc65aa903d44c588a9a2f470c48240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1083e9b1f8d949d7a0d8aba001f19c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f16b247cff23429496d81548b78213cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b62d28b9ba44ea1805ea97b9d2cf5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83c564de27c4ec790ba01b73e683588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5f834f7cd8243dd9572b6ed07ebc02c",
              "IPY_MODEL_d7e6aac9a119465087594f1b94834713",
              "IPY_MODEL_07c022f3837c40c98a38bf4eb4d19ae8"
            ],
            "layout": "IPY_MODEL_9a00def87e834e91ad031732295dcc6f"
          }
        },
        "c5f834f7cd8243dd9572b6ed07ebc02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d40b7e7ead8e4242a33e3f1902d9a257",
            "placeholder": "​",
            "style": "IPY_MODEL_4c26e5dc430143cbb11674f8772039ee",
            "value": "README.md: 100%"
          }
        },
        "d7e6aac9a119465087594f1b94834713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e2b0aef94e4fd6a3aef3fc44dc74ef",
            "max": 4087,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a39efb4ac0a4ca9bce437b58c831adb",
            "value": 4087
          }
        },
        "07c022f3837c40c98a38bf4eb4d19ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cd82dfbb604074b70d13685b823a2a",
            "placeholder": "​",
            "style": "IPY_MODEL_6d0310ff84324585a688a35dcdb772a7",
            "value": " 4.09k/4.09k [00:00&lt;00:00, 37.8kB/s]"
          }
        },
        "9a00def87e834e91ad031732295dcc6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40b7e7ead8e4242a33e3f1902d9a257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c26e5dc430143cbb11674f8772039ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e2b0aef94e4fd6a3aef3fc44dc74ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a39efb4ac0a4ca9bce437b58c831adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7cd82dfbb604074b70d13685b823a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0310ff84324585a688a35dcdb772a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13ef424c8b840c1aa58e027762f460c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b97d27876904f87a35ab63d17aab398",
              "IPY_MODEL_5e5b1f7c549946a098f3f64b4de5a64d",
              "IPY_MODEL_c17676bc69cc44ed986f6331a012a002"
            ],
            "layout": "IPY_MODEL_cfb8f83fcfec445d958007eb0b215fee"
          }
        },
        "7b97d27876904f87a35ab63d17aab398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d5e29407bf449298b93a8d71a914faf",
            "placeholder": "​",
            "style": "IPY_MODEL_5cea003dca1b4d9bbe817cc8b267c13b",
            "value": "generation_config.json: 100%"
          }
        },
        "5e5b1f7c549946a098f3f64b4de5a64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02f5b2edb9c476aa0a98abb48201f7a",
            "max": 121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7134aef8454b4bbba035a78739355e72",
            "value": 121
          }
        },
        "c17676bc69cc44ed986f6331a012a002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13f9c419380e486398b5266fa19a4e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_094bedab38b84376b354fb9ab2f135c2",
            "value": " 121/121 [00:00&lt;00:00, 1.81kB/s]"
          }
        },
        "cfb8f83fcfec445d958007eb0b215fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5e29407bf449298b93a8d71a914faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cea003dca1b4d9bbe817cc8b267c13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b02f5b2edb9c476aa0a98abb48201f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7134aef8454b4bbba035a78739355e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13f9c419380e486398b5266fa19a4e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094bedab38b84376b354fb9ab2f135c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a81997a7d204e1e8c23016daf3ce45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c51e5f8dbd1b4af2b602f975e68079ee",
              "IPY_MODEL_ef338cb1b4924b39ba56a9ca2f9f8afb",
              "IPY_MODEL_7e79e414856c4f09a01b5c06a05f9529"
            ],
            "layout": "IPY_MODEL_fdfd1384cd6f4556b2cfeccde7a8590f"
          }
        },
        "c51e5f8dbd1b4af2b602f975e68079ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295305472d044f81952f33134bf9d9b9",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb4f15c10c942028097a007d06f66db",
            "value": "future.jpg: 100%"
          }
        },
        "ef338cb1b4924b39ba56a9ca2f9f8afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0c382c8b7a641f4ae2a5cc8caa98c74",
            "max": 606528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1add2bae15f4f71a958c449186eda45",
            "value": 606528
          }
        },
        "7e79e414856c4f09a01b5c06a05f9529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a6eb1eddc74933b29c99e87d7b2f6b",
            "placeholder": "​",
            "style": "IPY_MODEL_6373de7a3d31405ab035437d55bc5892",
            "value": " 607k/607k [00:00&lt;00:00, 765kB/s]"
          }
        },
        "fdfd1384cd6f4556b2cfeccde7a8590f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295305472d044f81952f33134bf9d9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb4f15c10c942028097a007d06f66db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0c382c8b7a641f4ae2a5cc8caa98c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1add2bae15f4f71a958c449186eda45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7a6eb1eddc74933b29c99e87d7b2f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6373de7a3d31405ab035437d55bc5892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2025a848f4b1429bb053c2731dd0bd81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d64b6bf0f4514a33b64903af7f17ccab",
              "IPY_MODEL_4afc55ef689548839eab95332023bdd6",
              "IPY_MODEL_79ca4b3020df4ddbae2c2faba32548ce"
            ],
            "layout": "IPY_MODEL_73295c2926ff46db971fda0add16b1d3"
          }
        },
        "d64b6bf0f4514a33b64903af7f17ccab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8e97b584c74a819d2a41751ff466d8",
            "placeholder": "​",
            "style": "IPY_MODEL_1e51b3c50a1a48e9a647a0d6d1f90fa8",
            "value": "pytorch_model-00001-of-00004.bin: 100%"
          }
        },
        "4afc55ef689548839eab95332023bdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef5cd8123884d999ed4504f3db8c546",
            "max": 4976718466,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d62ec7b54a1476b8718bee2c1660739",
            "value": 4976718466
          }
        },
        "79ca4b3020df4ddbae2c2faba32548ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd77913ed8ee4b218f891580ce2a91fa",
            "placeholder": "​",
            "style": "IPY_MODEL_bd3e23a8b0784be18b35250ed92bfb7a",
            "value": " 4.98G/4.98G [03:14&lt;00:00, 16.8MB/s]"
          }
        },
        "73295c2926ff46db971fda0add16b1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8e97b584c74a819d2a41751ff466d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e51b3c50a1a48e9a647a0d6d1f90fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef5cd8123884d999ed4504f3db8c546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d62ec7b54a1476b8718bee2c1660739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd77913ed8ee4b218f891580ce2a91fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3e23a8b0784be18b35250ed92bfb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4bb98e4ebc43feb7f6630ee6b58f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f76ade7c030f48b29b8c3be019b87630",
              "IPY_MODEL_6db53c52e5ee4bfab01d8d83a096d6d2",
              "IPY_MODEL_dcfbf29270384575879f2d93459d0b32"
            ],
            "layout": "IPY_MODEL_fae4c6c94ad341bd9dc1ebef9c78443f"
          }
        },
        "f76ade7c030f48b29b8c3be019b87630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1bb25561f83486d93c7c2929ee323c0",
            "placeholder": "​",
            "style": "IPY_MODEL_c114f7e0e1eb41f3a7efd65fdefd2eba",
            "value": "pytorch_model-00002-of-00004.bin: 100%"
          }
        },
        "6db53c52e5ee4bfab01d8d83a096d6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f325c8da264e939d8e6fbe40c982a9",
            "max": 4999827590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_936b36f891434164921eb4dfa618f298",
            "value": 4999827590
          }
        },
        "dcfbf29270384575879f2d93459d0b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb12abf435c46358c92acdee2741924",
            "placeholder": "​",
            "style": "IPY_MODEL_6d06a9b9b38b498e88d554f203f0a609",
            "value": " 5.00G/5.00G [03:14&lt;00:00, 26.9MB/s]"
          }
        },
        "fae4c6c94ad341bd9dc1ebef9c78443f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1bb25561f83486d93c7c2929ee323c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c114f7e0e1eb41f3a7efd65fdefd2eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f325c8da264e939d8e6fbe40c982a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936b36f891434164921eb4dfa618f298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbb12abf435c46358c92acdee2741924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d06a9b9b38b498e88d554f203f0a609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6c2d5d9318b4202b4241c3e48024653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b14c908d865748198114c2aa9d945f3f",
              "IPY_MODEL_5353d06a3399415a966f1cd2734e7049",
              "IPY_MODEL_0edd3dd485de4bbfb7a37d23c3da3194"
            ],
            "layout": "IPY_MODEL_fa1da5703cb041108801c7c9bc47b9bf"
          }
        },
        "b14c908d865748198114c2aa9d945f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d1f1a5ce2d44a59b5cb534c2cc0818",
            "placeholder": "​",
            "style": "IPY_MODEL_c9571b0b445d4deda8338f10a79d25d8",
            "value": "pytorch_model-00003-of-00004.bin: 100%"
          }
        },
        "5353d06a3399415a966f1cd2734e7049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62365897684243adbdda83dded49b428",
            "max": 4915939146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd8bfa0dc7c34a9e84dc2eacbe9b2649",
            "value": 4915939146
          }
        },
        "0edd3dd485de4bbfb7a37d23c3da3194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc3378198e84211a91c2604200b4a67",
            "placeholder": "​",
            "style": "IPY_MODEL_3d2f5984856b41bc852f2d46892d8376",
            "value": " 4.92G/4.92G [03:10&lt;00:00, 27.0MB/s]"
          }
        },
        "fa1da5703cb041108801c7c9bc47b9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d1f1a5ce2d44a59b5cb534c2cc0818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9571b0b445d4deda8338f10a79d25d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62365897684243adbdda83dded49b428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8bfa0dc7c34a9e84dc2eacbe9b2649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cc3378198e84211a91c2604200b4a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2f5984856b41bc852f2d46892d8376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4887ba81927547cd842da318683e86cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c371bcfab2b4e4ab983ab45d973a6e4",
              "IPY_MODEL_d400606b53524cb2a22d0f976e4d8444",
              "IPY_MODEL_1d5deb293ece4d468a71c0bc8fbd7372"
            ],
            "layout": "IPY_MODEL_ad30264481a1495ca882d3c2d3e4e5bf"
          }
        },
        "5c371bcfab2b4e4ab983ab45d973a6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46be8f37e5ab4f3bba82a20a36535b29",
            "placeholder": "​",
            "style": "IPY_MODEL_85ba77cda6d545cb949e676d91a200b3",
            "value": "pytorch_model-00004-of-00004.bin: 100%"
          }
        },
        "d400606b53524cb2a22d0f976e4d8444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6dc913a1cc453b810655933c7b335f",
            "max": 1168140873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8a434bdb716490297f00bb4603d78e7",
            "value": 1168140873
          }
        },
        "1d5deb293ece4d468a71c0bc8fbd7372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f197cd51069247a586a26b1242f65bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_f77b70f135ca4c5b82e114da20032202",
            "value": " 1.17G/1.17G [00:46&lt;00:00, 25.1MB/s]"
          }
        },
        "ad30264481a1495ca882d3c2d3e4e5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46be8f37e5ab4f3bba82a20a36535b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ba77cda6d545cb949e676d91a200b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be6dc913a1cc453b810655933c7b335f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a434bdb716490297f00bb4603d78e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f197cd51069247a586a26b1242f65bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77b70f135ca4c5b82e114da20032202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9da5f201554403ebdef80de380176f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8a657c278de47c28635fc13a56c5149",
              "IPY_MODEL_22536fe061c849c093b8aea2f3384488",
              "IPY_MODEL_a7a1703a2eb7447daa149b5e84c78ad0"
            ],
            "layout": "IPY_MODEL_4d46f823dc0646a987308bf0765be9d7"
          }
        },
        "a8a657c278de47c28635fc13a56c5149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce912419b3e4b0490970915783d2bea",
            "placeholder": "​",
            "style": "IPY_MODEL_32ae980128ce44b08af1fd807788b1ce",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "22536fe061c849c093b8aea2f3384488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5302c1f72de4daf872de3f77bb344d1",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20b8323d567140048bd52a531e9c8ac6",
            "value": 23950
          }
        },
        "a7a1703a2eb7447daa149b5e84c78ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88741332c79147fa8db393e9b660b9da",
            "placeholder": "​",
            "style": "IPY_MODEL_9f590f063af14e69914593add7e10e66",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 471kB/s]"
          }
        },
        "4d46f823dc0646a987308bf0765be9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce912419b3e4b0490970915783d2bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ae980128ce44b08af1fd807788b1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5302c1f72de4daf872de3f77bb344d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b8323d567140048bd52a531e9c8ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88741332c79147fa8db393e9b660b9da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f590f063af14e69914593add7e10e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b98e4bdaf9b4dde8e83d17fe61290f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b44d08196ae44e289f4698075e015ae0",
              "IPY_MODEL_f0a161d4e4b14cecb45d16bc09f6227d",
              "IPY_MODEL_39f1a2b226764ab8ab62b2e578916b5b"
            ],
            "layout": "IPY_MODEL_3acf505e3bee497d87e82bbf7760e2cf"
          }
        },
        "b44d08196ae44e289f4698075e015ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5bb686a1b646638284c54b1dae6395",
            "placeholder": "​",
            "style": "IPY_MODEL_3628941016fe4bbb91ca1bcd52b622be",
            "value": "tokenizer.json: 100%"
          }
        },
        "f0a161d4e4b14cecb45d16bc09f6227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944f94c251aa410eb7a3d69b6d676442",
            "max": 9084463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c5e99afdd7a4dd5b2e35566bde0849d",
            "value": 9084463
          }
        },
        "39f1a2b226764ab8ab62b2e578916b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70f642ca4694b52ac5c2deb46330552",
            "placeholder": "​",
            "style": "IPY_MODEL_2b5f238a9aae4195964d78155a48a586",
            "value": " 9.08M/9.08M [00:01&lt;00:00, 6.35MB/s]"
          }
        },
        "3acf505e3bee497d87e82bbf7760e2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5bb686a1b646638284c54b1dae6395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3628941016fe4bbb91ca1bcd52b622be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944f94c251aa410eb7a3d69b6d676442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5e99afdd7a4dd5b2e35566bde0849d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70f642ca4694b52ac5c2deb46330552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5f238a9aae4195964d78155a48a586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3901db51e63142c6923891df7cb5da79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3877963d61414c98a333be689649855f",
              "IPY_MODEL_52e62cc474e142daa32bf309c81bd024",
              "IPY_MODEL_9040c9590c8a48fb99dca9ceab031e5d"
            ],
            "layout": "IPY_MODEL_df83305501f340ea88b1313f0c58f78e"
          }
        },
        "3877963d61414c98a333be689649855f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225eb9ad19844c0bb43086f50bfdd558",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f2ec55143b4f22837ca123c268e01b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "52e62cc474e142daa32bf309c81bd024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60dec5effb343ad90db88922fc56b06",
            "max": 449,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f03e176fbc63421fa908b478e9fbeaa3",
            "value": 449
          }
        },
        "9040c9590c8a48fb99dca9ceab031e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93567b3de3e64b66a5d27dd215a07011",
            "placeholder": "​",
            "style": "IPY_MODEL_90e68b5d78784602a019227f6504fecb",
            "value": " 449/449 [00:00&lt;00:00, 6.45kB/s]"
          }
        },
        "df83305501f340ea88b1313f0c58f78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225eb9ad19844c0bb43086f50bfdd558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f2ec55143b4f22837ca123c268e01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c60dec5effb343ad90db88922fc56b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03e176fbc63421fa908b478e9fbeaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93567b3de3e64b66a5d27dd215a07011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e68b5d78784602a019227f6504fecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc83d58390ff47cf8c8d05ef42e36a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d16c8b917067492cb0634304df90ffa5",
              "IPY_MODEL_3dfc437bf0144249bcd799979e6010c7",
              "IPY_MODEL_32ed590b15c04b5f9b696249b2259299"
            ],
            "layout": "IPY_MODEL_6ac307d5c9ae4ce68f258097d734fa48"
          }
        },
        "d16c8b917067492cb0634304df90ffa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd546286107840b68f2e698cab561f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_4804cd4f3b6d4a798aadc417c13bc0a9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3dfc437bf0144249bcd799979e6010c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b779add6a8f34e7dbdbf6156773fd930",
            "max": 50599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15824965122045de98d620e1046f3d37",
            "value": 50599
          }
        },
        "32ed590b15c04b5f9b696249b2259299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d729e9840eaf455f8582ca0ab2b7c2f2",
            "placeholder": "​",
            "style": "IPY_MODEL_10ade03f95db45d3b39a7e512db4e8da",
            "value": " 50.6k/50.6k [00:00&lt;00:00, 246kB/s]"
          }
        },
        "6ac307d5c9ae4ce68f258097d734fa48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd546286107840b68f2e698cab561f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4804cd4f3b6d4a798aadc417c13bc0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b779add6a8f34e7dbdbf6156773fd930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15824965122045de98d620e1046f3d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d729e9840eaf455f8582ca0ab2b7c2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ade03f95db45d3b39a7e512db4e8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7672b0ac3e4407f8869440328f6c67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbdba2df173a485c8a8c95c4fc873608",
              "IPY_MODEL_fde6b38dc06943b48ca8cd350a868e01",
              "IPY_MODEL_099f2d4b14ec4f8e90a29311feb5d05f"
            ],
            "layout": "IPY_MODEL_de6c914e251c45e0aec29d826d96a9c5"
          }
        },
        "dbdba2df173a485c8a8c95c4fc873608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77956ae89834deaa0666c2c7cfde231",
            "placeholder": "​",
            "style": "IPY_MODEL_655a28fce2ee4695b23f455e5fee4d5c",
            "value": "Medical-Llama3-8B-GGUF.Q4_0.gguf: 100%"
          }
        },
        "fde6b38dc06943b48ca8cd350a868e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57fb5f6b00ff47b3bef3435e8b11bf68",
            "max": 4661724032,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f444cd04b4764a3b9a5aa798a6b0f386",
            "value": 4661724032
          }
        },
        "099f2d4b14ec4f8e90a29311feb5d05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d911f2a9a2a48a890fc56fb2eb7b484",
            "placeholder": "​",
            "style": "IPY_MODEL_6b3400846dba4ca88cac2b105e2eb4bd",
            "value": " 4.66G/4.66G [03:00&lt;00:00, 26.5MB/s]"
          }
        },
        "de6c914e251c45e0aec29d826d96a9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77956ae89834deaa0666c2c7cfde231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655a28fce2ee4695b23f455e5fee4d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57fb5f6b00ff47b3bef3435e8b11bf68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f444cd04b4764a3b9a5aa798a6b0f386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d911f2a9a2a48a890fc56fb2eb7b484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3400846dba4ca88cac2b105e2eb4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcec2e54a9b34e048fcd9fa7f7f32d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ec2783147fa40969b85dad071964d98",
              "IPY_MODEL_5e9e7f3b5b464a1990947785672e64cf",
              "IPY_MODEL_070dfa7bb31b46689d8e17958ef5578f"
            ],
            "layout": "IPY_MODEL_87697391b8cb49b8a75f96a4dd71f130"
          }
        },
        "5ec2783147fa40969b85dad071964d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc8d21cd835471fb02e54f6dc6487ca",
            "placeholder": "​",
            "style": "IPY_MODEL_d17b30cf95324384a1f784d167b7f698",
            "value": "llama-2-13b-chat.ggmlv3.q5_1.bin: 100%"
          }
        },
        "5e9e7f3b5b464a1990947785672e64cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df9633c585a04a909e94a3f633882fc8",
            "max": 9763701888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ab8395b984d41ee97351f14183f0aeb",
            "value": 9763701888
          }
        },
        "070dfa7bb31b46689d8e17958ef5578f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b5a62f28c9457f83f027bd9217f21d",
            "placeholder": "​",
            "style": "IPY_MODEL_233c124324be449da00a5370d8d6bf38",
            "value": " 9.76G/9.76G [02:37&lt;00:00, 60.1MB/s]"
          }
        },
        "87697391b8cb49b8a75f96a4dd71f130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc8d21cd835471fb02e54f6dc6487ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17b30cf95324384a1f784d167b7f698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df9633c585a04a909e94a3f633882fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab8395b984d41ee97351f14183f0aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8b5a62f28c9457f83f027bd9217f21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233c124324be449da00a5370d8d6bf38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}